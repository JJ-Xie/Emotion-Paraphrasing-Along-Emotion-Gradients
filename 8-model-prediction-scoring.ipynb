{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cf606e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers==2.11.0\n",
      "  Using cached transformers-2.11.0-py3-none-any.whl (674 kB)\n",
      "Requirement already satisfied: requests in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (2.26.0)\n",
      "Requirement already satisfied: packaging in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (21.0)\n",
      "Requirement already satisfied: numpy in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (1.19.5)\n",
      "Requirement already satisfied: filelock in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (0.0.45)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (2021.8.3)\n",
      "Requirement already satisfied: sentencepiece in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (0.1.96)\n",
      "Collecting tokenizers==0.7.0\n",
      "  Using cached tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from transformers==2.11.0) (4.62.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from packaging->transformers==2.11.0) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from requests->transformers==2.11.0) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from requests->transformers==2.11.0) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from requests->transformers==2.11.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from requests->transformers==2.11.0) (3.2)\n",
      "Requirement already satisfied: joblib in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from sacremoses->transformers==2.11.0) (1.0.1)\n",
      "Requirement already satisfied: six in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n",
      "Requirement already satisfied: click in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from sacremoses->transformers==2.11.0) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from click->sacremoses->transformers==2.11.0) (4.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.11.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.11.0) (3.5.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: transformers 4.25.1\n",
      "    Uninstalling transformers-4.25.1:\n",
      "      Successfully uninstalled transformers-4.25.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "simpletransformers 0.63.6 requires transformers>=4.6.0, but you have transformers 2.11.0 which is incompatible.\n",
      "bert-score 0.3.11 requires transformers>=3.0.0numpy, but you have transformers 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.7.0 transformers-2.11.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/xie/.pyenv/versions/3.7.8/lib/python3.7/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installs older transformers version for GoEmotions compatability\n",
    "!pip install transformers==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e39b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0M'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activates CUDA for GPU use by GoEmotions\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e533c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "# Initializes a GoEmotions model instance\n",
    "import transformers\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "from GoEmotions.model import BertForMultiLabelClassification\n",
    "from GoEmotions.multilabel_pipeline import MultiLabelPipeline\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-original\")\n",
    "\n",
    "goemotions = MultiLabelPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    threshold=0.3,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf053d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset used to train model (mix, twit0.825, or combined): mix\n",
      "Training type of model (regular or limited): regular\n",
      "Number of epochs trained on model: 3\n",
      "Dataset for prediction generation (mix, twit0.825, or combined): mix\n"
     ]
    }
   ],
   "source": [
    "# Allows user to select a model and the predictions it had on an evaluation set\n",
    "model_dataset = input('Dataset used to train model (mix, twit0.825, or combined): ')\n",
    "training_type = input('Training type of model (regular or limited): ')\n",
    "epochs = int(input('Number of epochs trained on model: '))\n",
    "model_name = f\"{training_type}-{model_dataset}-{epochs}epochs\"\n",
    "\n",
    "testing_set = input('Dataset for prediction generation (mix, twit0.825, or combined): ')\n",
    "\n",
    "if training_type.lower() == 'regular':\n",
    "    train_set = 'training'\n",
    "    eval_set = 'testing'\n",
    "elif training_type.lower() == 'limited':\n",
    "    train_set = 'testing'\n",
    "    eval_set = 'training'\n",
    "else:\n",
    "    print('Please enter a valid training type')\n",
    "\n",
    "def print_base_info(model_name, testing_set):\n",
    "    print(f'---- Scoring Predictions ----')\n",
    "    print(f'Model: {model_name}')\n",
    "    print(f'Test Set: {testing_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3895f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this step if it is using BART\n",
    "model_name = model_name + \"-bart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960be6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Labeling Predictions for Model: regular-mix-3epochs-bart on Dataset: mix ----\n"
     ]
    }
   ],
   "source": [
    "# Labels the target and predicted texts for scoring by emotion transition and paraphrasing metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Same Sigmoid Function for determining the emotion of a text\n",
    "threshold = 0.5\n",
    "def Top_Score_Label (outputs):\n",
    "    scores = 1 / (1 + np.exp(-outputs))  # Sigmoid\n",
    "    top_score = 0\n",
    "    top_label = \"\"\n",
    "    for item in scores:\n",
    "        for idx, s in enumerate(item):\n",
    "            if s > threshold:\n",
    "                if s > top_score: \n",
    "                    top_label = model.config.id2label[idx]\n",
    "    return top_label\n",
    "\n",
    "print(f'---- Labeling Predictions for Model: {model_name} on Dataset: {testing_set} ----')\n",
    "\n",
    "df = pd.read_csv(f'predictions-data/{model_name}/{testing_set}-predictions.tsv', sep='\\t').astype(str) \n",
    "\n",
    "\n",
    "# Labels target and prediction emotions\n",
    "target_labels = []\n",
    "prediction_labels = []\n",
    "for index, row in df.iterrows():\n",
    "    # Ensures the text are within the token limit of 512\n",
    "    t_text = (row.target_text[:512] + '..') if len(row.target_text) > 512 else row.target_text\n",
    "    p_text = (row.predictions[:512] + '..') if len(row.predictions) > 512 else row.predictions\n",
    "\n",
    "    # Uses GoEmotions to label potential emotions of target and prediction text\n",
    "    target_emo = goemotions(t_text)\n",
    "    prediction_emo = goemotions(p_text)\n",
    "\n",
    "    # Finds best emotion for each text\n",
    "    target_label = Top_Score_Label(target_emo)\n",
    "    prediction_label = Top_Score_Label(prediction_emo)\n",
    "\n",
    "    target_labels.append(target_label)\n",
    "    prediction_labels.append(prediction_label)\n",
    "\n",
    "    \n",
    "# Adds target and prediction emotion labels to dataframe    \n",
    "df[\"target_emo\"] = target_labels \n",
    "df[\"prediction_emo\"] = prediction_labels\n",
    "\n",
    "# Saves the file with new labels to new location in preparation for scoring\n",
    "df.to_csv(f'predictions-data/{model_name}/{testing_set}-prediction_emo.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3695805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---- Scoring Predictions ----\n",
      "Model: regular-mix-3epochs-bart\n",
      "Test Set: mix\n",
      "'Exact Score'\n",
      "0.317344589409056\n",
      "'BLEU Score'\n",
      "0.24106641931166153\n",
      "'Google BLEU Score'\n",
      "0.2645182357078268\n",
      "'ROUGE1 Score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5426834674512404\n",
      "'ROUGE2 Score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3123791723432929\n",
      "'ROUGEL Score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4958498848778997\n",
      "'METEOR Score'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/xie/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/xie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/xie/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5238469173911132\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uses HuggingFace's Evaluate package to score \n",
    "# emotion transition and paraphrasing capabilities of the given models and evaluation sets\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "from pprint import pprint\n",
    "from statistics import mean\n",
    "\n",
    "# Exact Match scores emotion transition\n",
    "def exact(truths, preds):\n",
    "    exact = evaluate.load('exact_match')\n",
    "    result = exact.compute(predictions = preds, references = truths)['exact_match']\n",
    "    return result\n",
    "\n",
    "# BLEU, Google_BLEU, ROUGE, and METEOR score paraphrasing\n",
    "def bleu(truths, preds):\n",
    "    bleu = evaluate.load('bleu')\n",
    "    result = bleu.compute(predictions = preds, references = truths)['bleu']\n",
    "    return result\n",
    "\n",
    "def google_bleu(truths, preds):\n",
    "    google_bleu = evaluate.load('google_bleu')\n",
    "    result = google_bleu.compute(predictions = preds, references = truths)['google_bleu']\n",
    "    return result\n",
    "\n",
    "def rouge1(truths, preds):\n",
    "    rouge = evaluate.load('rouge')\n",
    "    result = rouge.compute(predictions = preds, references = truths)['rouge1']\n",
    "    return result\n",
    "    \n",
    "def rouge2(truths, preds):\n",
    "    rouge = evaluate.load('rouge')\n",
    "    result = rouge.compute(predictions = preds, references = truths)['rouge2']\n",
    "    return result\n",
    "    \n",
    "def rougeL(truths, preds):\n",
    "    rouge = evaluate.load('rouge')\n",
    "    result = rouge.compute(predictions = preds, references = truths)['rougeL']\n",
    "    return result\n",
    "\n",
    "def bertscore(truths, preds):\n",
    "    bscore = evaluate.load('bertscore')\n",
    "    result = bscore.compute(predictions = preds, references = truths, model_type=\"distilbert-base-uncased\")\n",
    "    return result\n",
    "\n",
    "def meteor(truths, preds):\n",
    "    meteor = evaluate.load('meteor')\n",
    "    result = meteor.compute(predictions = preds, references = truths)['meteor']\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print_base_info(model_name, testing_set)\n",
    "    \n",
    "df = pd.read_csv(f'predictions-data/{model_name}/{testing_set}-prediction_emo.tsv', sep='\\t').astype(str)\n",
    "\n",
    "# Prints all scores of a model's performance\n",
    "pprint(\"Exact Score\")\n",
    "pprint(exact(df[\"target_emo\"], df[\"prediction_emo\"]))\n",
    "\n",
    "pprint(\"BLEU Score\")\n",
    "pprint(bleu(df[\"target_text\"], df[\"predictions\"]))\n",
    "\n",
    "pprint('Google BLEU Score')\n",
    "pprint(google_bleu(df[\"target_text\"], df[\"predictions\"]))\n",
    "\n",
    "pprint('ROUGE1 Score')\n",
    "pprint(rouge1(df[\"target_text\"], df[\"predictions\"]))\n",
    "\n",
    "pprint('ROUGE2 Score')\n",
    "pprint(rouge2(df[\"target_text\"], df[\"predictions\"]))\n",
    "\n",
    "pprint('ROUGEL Score')\n",
    "pprint(rougeL(df[\"target_text\"], df[\"predictions\"]))\n",
    "\n",
    "pprint('METEOR Score')\n",
    "pprint(meteor(df[\"target_text\"], df[\"predictions\"]))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df37fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
