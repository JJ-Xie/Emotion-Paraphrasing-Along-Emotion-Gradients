{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ccbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = input('Dataset to train model (mix, twit0.825 or combined):  ')\n",
    "training_type = input('Regular or limited training (regular or limited): ')\n",
    "epochs = int(input('Number of training epochs: '))\n",
    "\n",
    "testing_set = input('Dataset for prediction generation (mix, twit0.825, or combined): ')\n",
    "\n",
    "if training_type.lower() == 'regular':\n",
    "    train_set = 'training'\n",
    "    eval_set = 'testing'\n",
    "elif training_type.lower() == 'limited':\n",
    "    train_set = 'testing'\n",
    "    eval_set = 'training'\n",
    "else:\n",
    "    print('Please enter a valid training type')\n",
    "    \n",
    "emo_filter_list = [\n",
    "                   'sid', \n",
    "                   'sid_rg', \n",
    "                   'emo', \n",
    "                   'emo_sid', \n",
    "                   'emo_sid_tg', \n",
    "                   'emo_sid_tg_nn', \n",
    "                   'emo_sid_tg_ge', \n",
    "                   'emo_sid_tg_nn_ge'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc49a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from simpletransformers.t5 import T5Model\n",
    "\n",
    "def genPredictions(model_emo_filter, eval_emo_filter):\n",
    "    model_name = f\"{training_type}-{model_dataset}-{model_emo_filter}-{epochs}epochs\"\n",
    "    print(f'---- Generating Predictions for Model: {model_name}  on Dataset: {testing_set}-{eval_emo_filter}----')\n",
    "    model_args = {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"max_seq_length\": 196,\n",
    "        \"eval_batch_size\": 32,\n",
    "        \"num_train_epochs\": 1,\n",
    "        \"use_multiprocessing\": False,\n",
    "        \"num_beams\": None,\n",
    "        \"do_sample\": True,\n",
    "        \"max_length\": 50,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.95,\n",
    "        \"num_return_sequences\": 3,\n",
    "    }\n",
    "\n",
    "    model = T5Model(\"t5\", model_name, args=model_args)\n",
    "    df = pd.read_csv(f'emotion-labeled-data/{model_dataset}/{testing_set}-{eval_emo_filter}-{eval_set}_t5.tsv', sep=\"\\t\").astype(str)\n",
    "\n",
    "    to_predict = [\n",
    "        prefix + \": \" + str(input_text)\n",
    "        for prefix, input_text in zip(df[\"prefix\"].tolist(), df[\"input_text\"].tolist())\n",
    "    ]\n",
    "\n",
    "    preds = model.predict(to_predict)\n",
    "    preds = [pred[0] for pred in preds]\n",
    "    df[\"predictions\"] = preds\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    path = f'predictions-data/{model_name}'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    df.to_csv(f'predictions-data/{model_name}/{testing_set}-{eval_emo_filter}-predictions.tsv', sep=\"\\t\")\n",
    "    \n",
    "    \n",
    "for emo_filter in emo_filter_list:\n",
    "    genPredictions(emo_filter, emo_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fdb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba996c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline, AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "def clean_paraphrased(prefix, input_text):\n",
    "    outputs = generator('<s>'+ prefix +': ' + input_text + '</s>>>>><p>', max_length=100, num_return_sequences=2, return_full_text=True)\n",
    "    return outputs[0]['generated_text'].split('</s>>>>><p>')[1].split('</p>')[0]\n",
    "\n",
    "def genGPT(model_emo_filter, eval_emo_filter):\n",
    "    model_name = f\"{training_type}-{model_dataset}-{model_emo_filter}-{epochs}epochs-gpt\"\n",
    "    print(f'---- Generating Predictions for Model: {model_name}  on Dataset: {testing_set}-{eval_emo_filter}----')\n",
    "    df = pd.read_csv(f'emotion-labeled-data/{model_dataset}/{testing_set}-{eval_emo_filter}-{eval_set}_t5.tsv', encoding='utf-8', sep=\"\\t\")\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if index % 1000 == 0:\n",
    "            print('Row: ' + str(index))\n",
    "            \n",
    "        prefix = row.prefix\n",
    "        input_text = row.input_text\n",
    "        predictions.append(clean_paraphrased(prefix, input_text))\n",
    "        \n",
    "    df[\"predictions\"] = predictions\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    path = f'predictions-data/{model_name}'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    df.to_csv(f'predictions-data/{model_name}/{testing_set}-{eval_emo_filter}-predictions.tsv', sep=\"\\t\")\n",
    "    \n",
    "for emo_filter in emo_filter_list:\n",
    "    model = AutoModelWithLMHead.from_pretrained(f\"{training_type}-{model_dataset}-{emo_filter}-{epochs}epochs-gpt\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    generator = pipeline(task='text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "    genGPT(emo_filter, emo_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d83be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
