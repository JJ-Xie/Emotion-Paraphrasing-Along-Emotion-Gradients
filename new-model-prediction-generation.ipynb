{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "str(torch.cuda.memory_allocated(device)/1000000 ) + 'M'\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ccbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = input('Dataset to train model (mix, twit0.825 or combined):  ')\n",
    "training_type = input('Regular or limited training (regular or limited): ')\n",
    "epochs = int(input('Number of training epochs: '))\n",
    "\n",
    "testing_set = input('Dataset for prediction generation (mix, twit0.825, or combined): ')\n",
    "\n",
    "if training_type.lower() == 'regular':\n",
    "    train_set = 'training'\n",
    "    eval_set = 'testing'\n",
    "elif training_type.lower() == 'limited':\n",
    "    train_set = 'testing'\n",
    "    eval_set = 'training'\n",
    "else:\n",
    "    print('Please enter a valid training type')\n",
    "    \n",
    "emo_filter_list = [\n",
    "#                   't5',\n",
    "                   'bart',\n",
    "#                   'gpt', \n",
    "#                   'nil',\n",
    "#                   'sid',\n",
    "#                   'sid_rg', \n",
    "                   'emo', \n",
    "                   'emo_ge',\n",
    "#                   'emo_nn',\n",
    "#                   'emo_sid', \n",
    "#                   'emo_sid_nn',\n",
    "#                   'emo_sid_tg', \n",
    "#                   'emo_sid_tg_nn', \n",
    "#                   'emo_sid_tg_ge', \n",
    "#                   'emo_sid_tg_nn_ge'\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc49a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate predictions with fine-tuned T5 models \n",
    "import pandas as pd\n",
    "import os\n",
    "from simpletransformers.t5 import T5Model\n",
    "\n",
    "def genPredictions(model_emo_filter, eval_emo_filter):\n",
    "    if (model_emo_filter == 't5'): \n",
    "        model_name = 't5-base' \n",
    "    else:\n",
    "        model_name = f\"{training_type}-{model_dataset}-{model_emo_filter}-{epochs}epochs\"\n",
    "    print(f'---- Generating Predictions for Model: {model_name}  on Dataset: {testing_set}-{eval_emo_filter}----')\n",
    "    model_args = {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"max_seq_length\": 196,\n",
    "        \"eval_batch_size\": 32,\n",
    "        \"num_train_epochs\": 1,\n",
    "        \"use_multiprocessing\": False,\n",
    "        \"num_beams\": None,\n",
    "        \"do_sample\": True,\n",
    "        \"max_length\": 50,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.95,\n",
    "        \"num_return_sequences\": 3,\n",
    "    }\n",
    "\n",
    "    model = T5Model(\"t5\", model_name, args=model_args)\n",
    "    df = pd.read_csv(f'emotion-labeled-data/{model_dataset}/{testing_set}-{eval_emo_filter}-{eval_set}_t5.tsv', sep=\"\\t\").astype(str)\n",
    "\n",
    "    if (model_emo_filter == 't5'): \n",
    "        to_predict = [\n",
    "#            \"Paraphrase: \" + str(input_text)\n",
    "            prefix + \": \" + str(input_text)\n",
    "            for prefix, input_text in zip(df[\"prefix\"].tolist(), df[\"input_text\"].tolist())\n",
    "        ]\n",
    "    else:\n",
    "        to_predict = [\n",
    "            prefix + \": \" + str(input_text)\n",
    "            for prefix, input_text in zip(df[\"prefix\"].tolist(), df[\"input_text\"].tolist())\n",
    "        ]\n",
    "        \n",
    "    preds = model.predict(to_predict)\n",
    "    preds = [pred[0] for pred in preds]\n",
    "\n",
    "    if (model_emo_filter == 't5'): \n",
    "        new_preds = []\n",
    "        for pred in preds: \n",
    "            new_pred = pred[pred.rfind(':')+1:]\n",
    "            new_preds.append(new_pred)\n",
    "        preds = new_preds \n",
    "        \n",
    "    df[\"predictions\"] = preds\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    path = f'predictions-data/{model_name}'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    df.to_csv(f'predictions-data/{model_name}/{testing_set}-{eval_emo_filter}-predictions.tsv', sep=\"\\t\")\n",
    "    \n",
    "    \n",
    "for emo_filter in emo_filter_list:\n",
    "    if (emo_filter == 't5'): \n",
    "#        genPredictions('t5', 'nil')\n",
    "        genPredictions('t5', 'emo')\n",
    "        genPredictions('t5', 'emo_ge')\n",
    "#        genPredictions('nil', 'emo_ge')\n",
    "    else: \n",
    "        genPredictions(emo_filter, emo_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0814b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "genPredictions('nil', 'emo_ge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genPredictions('emo', 'emo_sid_tg_nn')\n",
    "genPredictions('emo_ge', 'emo_sid_tg_nn_ge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bfcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genPredictions('emo', 'emo')\n",
    "genPredictions('emo_ge', 'emo_ge')\n",
    "genPredictions('t5', 'emo')\n",
    "genPredictions('t5', 'emo_ge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee91a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "genPredictions('t5', 'emo_sid_tg_nn_ge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genPredictions('emo', 'emo_sid_tg_nn') \n",
    "genPredictions('emo_nn', 'emo_sid_tg_nn') \n",
    "genPredictions('emo_sid', 'emo_sid_tg_nn') \n",
    "genPredictions('emo_sid_nn', 'emo_sid_tg_nn') \n",
    "genPredictions('emo_sid_tg', 'emo_sid_tg_nn') \n",
    "genPredictions('emo_sid_tg_nn', 'emo_sid_tg_nn') \n",
    "genPredictions('emo_sid_tg_ge', 'emo_sid_tg_nn_ge') \n",
    "genPredictions('emo_sid_tg_nn_ge', 'emo_sid_tg_nn_ge') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0015f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02cd869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with fine-tuned Bart models \n",
    "import pandas as pd\n",
    "import os\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "\n",
    "def genPredictions(model_emo_filter, eval_emo_filter):\n",
    "    if (model_emo_filter == 'bart'): \n",
    "        model_name = \"facebook/bart-base\" \n",
    "    else:\n",
    "        model_name = f\"{training_type}-{model_dataset}-{model_emo_filter}-{epochs}epochs-bart\"\n",
    "    print(f'---- Generating Predictions for Model: {model_name}  on Dataset: {testing_set}-{eval_emo_filter}----')\n",
    "    model_args = {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"max_seq_length\": 196,\n",
    "        \"eval_batch_size\": 32,\n",
    "        \"num_train_epochs\": 1,\n",
    "        \"use_multiprocessing\": False,\n",
    "        \"num_beams\": None,\n",
    "        \"do_sample\": True,\n",
    "        \"max_length\": 50,\n",
    "        \"top_k\": 50,\n",
    "        \"top_p\": 0.95,\n",
    "        \"num_return_sequences\": 3,\n",
    "    }\n",
    "\n",
    "    model = Seq2SeqModel(\n",
    "        encoder_decoder_type=\"bart\",\n",
    "        encoder_decoder_name=model_name,\n",
    "        args=model_args,\n",
    "    )\n",
    "    df = pd.read_csv(f'emotion-labeled-data/{model_dataset}/{testing_set}-{eval_emo_filter}-{eval_set}_t5.tsv', sep=\"\\t\").astype(str)\n",
    "\n",
    "    if (model_emo_filter == 'bart'): \n",
    "        to_predict = [\n",
    "#            \"Paraphrase: \" + str(input_text)\n",
    "            prefix + \": \" + str(input_text)\n",
    "            for prefix, input_text in zip(df[\"prefix\"].tolist(), df[\"input_text\"].tolist())\n",
    "        ]\n",
    "    else:\n",
    "        to_predict = [\n",
    "            prefix + \": \" + str(input_text)\n",
    "            for prefix, input_text in zip(df[\"prefix\"].tolist(), df[\"input_text\"].tolist())\n",
    "        ]\n",
    "        \n",
    "    preds = model.predict(to_predict)\n",
    "    preds = [pred[0] for pred in preds]\n",
    "\n",
    "#    if (model_emo_filter == 'bart'): \n",
    "    new_preds = []\n",
    "    for pred in preds: \n",
    "         new_pred = pred[pred.rfind(':')+1:]\n",
    "         new_preds.append(new_pred)\n",
    "    preds = new_preds \n",
    "        \n",
    "    df[\"predictions\"] = preds\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    path = f'predictions-data/{model_name}'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    df.to_csv(f'predictions-data/{model_name}/{testing_set}-{eval_emo_filter}-predictions.tsv', sep=\"\\t\")\n",
    "    \n",
    "    \n",
    "for emo_filter in emo_filter_list:\n",
    "    if (emo_filter == 'bart'): \n",
    "#       genPredictions('bart', 'nil')\n",
    "        genPredictions('bart', 'emo')\n",
    "        genPredictions('bart', 'emo_ge')\n",
    "#       genPredictions('nil', 'emo_ge')\n",
    "    else: \n",
    "        genPredictions(emo_filter, emo_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fdb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba996c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions with fine-tuned GPT2 models \n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline, AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "def clean_paraphrased(prefix, input_text):\n",
    "    outputs = generator('<s>'+ prefix +': ' + input_text + '</s>>>>><p>', max_length=100, num_return_sequences=2, return_full_text=True)\n",
    "    return outputs[0]['generated_text'].split('</s>>>>><p>')[1].split('</p>')[0]\n",
    "\n",
    "def genGPT(model_emo_filter, eval_emo_filter):\n",
    "    if (model_emo_filter == 'gpt'): \n",
    "        model_name = \"gpt\" \n",
    "    else:\n",
    "        model_name = f\"{training_type}-{model_dataset}-{model_emo_filter}-{epochs}epochs-gpt\"\n",
    "    print(f'---- Generating Predictions for Model: {model_name}  on Dataset: {testing_set}-{eval_emo_filter}----')\n",
    "    df = pd.read_csv(f'emotion-labeled-data/{model_dataset}/{testing_set}-{eval_emo_filter}-{eval_set}_t5.tsv', encoding='utf-8', sep=\"\\t\")\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if index % 1000 == 0:\n",
    "            print('Row: ' + str(index))\n",
    "            \n",
    "        prefix = row.prefix\n",
    "        input_text = row.input_text\n",
    "        predictions.append(clean_paraphrased(prefix, input_text))\n",
    "        \n",
    "    df[\"predictions\"] = predictions\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    path = f'predictions-data/{model_name}'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    df.to_csv(f'predictions-data/{model_name}/{testing_set}-{eval_emo_filter}-predictions.tsv', sep=\"\\t\")\n",
    "    \n",
    "for emo_filter in emo_filter_list:\n",
    "    if (emo_filter == 'gpt'):\n",
    "        model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        generator = pipeline(task='text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "        genGPT(emo_filter, 'emo')\n",
    "        genGPT(emo_filter, 'emo_ge')\n",
    "    else: \n",
    "        model = AutoModelWithLMHead.from_pretrained(f\"{training_type}-{model_dataset}-{emo_filter}-{epochs}epochs-gpt\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "        generator = pipeline(task='text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "        genGPT(emo_filter, emo_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d83be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
